{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, ExtraTreesClassifier\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from sklearn.metrics import classification_report as cr,confusion_matrix, roc_auc_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from pyod.models.iforest import IForest\n",
    "le = LabelEncoder()\n",
    "scale = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_type_feats = pkl.load(open('./action_type_featuers.pkl', 'rb'))\n",
    "service_type_feats = pkl.load(open('./target_type_featuers.pkl', 'rb'))\n",
    "combined_feats = list(set(action_type_feats + service_type_feats))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data from the 5 users considered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user1 = pd.read_csv('./first_user_master.csv', usecols = combined_feat )\n",
    "user2 = pd.read_csv('./second_user_master.csv', usecols = combined_feat)\n",
    "user3 = pd.read_csv('./third_user_master.csv', usecols = combined_feat)\n",
    "user4 = pd.read_csv('./fourth_user_master.csv', usecols = combined_feat)\n",
    "user5 = pd.read_csv('./fifth_User_master.csv', usecols = combined_feat)\n",
    "data = pd.concat([user1, user2, user3, user4, user5])\n",
    "\n",
    "# Drop the userid and the ground truth variables\n",
    "action_drop = list(set(service_type_feats + ['userid','actiontype']))\n",
    "service_drop = list(set(action_type_feats + ['userid', 'service_type']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results for predicting malicious behaviour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "normalize = 'Yes'\n",
    "sampling = \"No\"\n",
    "user = 'MultiUser'\n",
    "table_columns = pkl.load(open('./table_columns.pkl', 'rb'))\n",
    "classifiers = {'ExtraTrees': ExtraTreesClassifier(),\n",
    "               'RandomForest': RandomForestClassifier(),\n",
    "               'XGBClassifier':XGBClassifier(),\n",
    "               'DecisionTreeClassifier': DecisionTreeClassifier(),\n",
    "               'IForest': IForest(n_estimators=100,max_samples='auto',verbose=2),\n",
    "              }\n",
    "\n",
    "X = data.drop(action_drop, axis = 1)\n",
    "y = data['actiontype']\n",
    "X = scale.fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and testing different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for clf in classifiers:\n",
    "    \n",
    "    curr_clas = classifiers[clf]\n",
    "    print('User', user, 'Normalize ' , normalize , 'Classifier ', clf, 'sampling', sampling)\n",
    "    curr_clas.fit(X_train, y_train)\n",
    "    y_predict = curr_clas.predict(X_test)\n",
    "    \n",
    "    report = cr(y_test, y_predict, target_names=['benign','malicious'], output_dict=True)\n",
    "    confusion_mat = confusion_matrix(y_test, y_predict)\n",
    "    auc_score = roc_auc_score(y_test, y_predict)\n",
    "\n",
    "    results.append([clf,\n",
    "                    user,\n",
    "                    user,\n",
    "                    normalize,\n",
    "                    sampling,\n",
    "                    report['benign']['precision'],\n",
    "                    report['benign']['recall'],\n",
    "                    report['benign']['f1-score'],\n",
    "                    report['benign']['support'],\n",
    "                    report['malicious']['precision'],\n",
    "                    report['malicious']['recall'],\n",
    "                    report['malicious']['f1-score'],\n",
    "                    report['malicious']['support'],\n",
    "                    report['macro avg']['precision'],\n",
    "                    report['macro avg']['recall'],\n",
    "                    report['macro avg']['f1-score'],\n",
    "                    report['macro avg']['support'],\n",
    "                    report['weighted avg']['precision'],\n",
    "                    report['weighted avg']['recall'],\n",
    "                    report['weighted avg']['f1-score'],\n",
    "                    report['weighted avg']['support'],\n",
    "                    report['accuracy'],\n",
    "                    confusion_mat[0][0],\n",
    "                    confusion_mat[0][1],\n",
    "                    confusion_mat[1][0],\n",
    "                    confusion_mat[1][1],\n",
    "                    auc_score,\n",
    "                    X_train.shape])\n",
    "\n",
    "actiontype_results  = pd.DataFrame(results, columns = table_columns)\n",
    "actiontype_results.to_csv(\"./actiontype_results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipelining the results from the best model for predicting malware for target classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "et = ExtraTreesClassifier()\n",
    "X = data.drop(['actiontype'], axis = 1)\n",
    "y = data['actiontype']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "et.fit(X_train.drop(action_drop, axis = 1), y_train)\n",
    "y_predict = et.predict(X_test.drop(action_drop, axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['predicted_actiontype'] = y_predict\n",
    "X_test['actual_actiontype'] = y_test \n",
    "X_test.reset_index(inplace=  True, drop =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data required for target classification\n",
    "service_type_data = X_test[X_test['predicted_actiontype'] == 1]\n",
    "target_classification_data = service_type_data.drop(service_drop, axis = 1)\n",
    "target_classification_data.drop(['actual_actiontype','predicted_actiontype'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and testing on different models for target classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "user =\"Multiuser\"\n",
    "normalize = \"Yes\"\n",
    "service_table_columns = pkl.load(open('./service_table_columns.pkl', 'rb'))\n",
    "classifiers = {'ExtraTrees': ExtraTreesClassifier(n_estimators=13),\n",
    "               'GradientBoosting': GradientBoostingClassifier(),\n",
    "               'XGBClassifier':XGBClassifier(random_state=8055),\n",
    "               'KNeighborsClassifier':KNeighborsClassifier(n_neighbors=3),              \n",
    "              }\n",
    "sampler =  {'RandomOverSampler':RandomOverSampler(),\n",
    "            'RandomUnderSamplerder':RandomUnderSampler()}\n",
    "\n",
    "X = target_classification_data.drop(['service_type'], axis = 1)\n",
    "y = target_classification_data[\"service_type\"]\n",
    "X = scale.fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 34123, test_size=0.25)    \n",
    "\n",
    "for clf in classifiers:\n",
    "    curr_clas = classifiers[clf]\n",
    "    for sampling in sampler:\n",
    "        curr_sampler = sampler[sampling]\n",
    "        X_train_sample, y_train_sample = curr_sampler.fit_sample(X_train, y_train)\n",
    "        curr_clas.fit(X_train_sample, y_train_sample)\n",
    "        y_predict = curr_clas.predict(X_test)\n",
    "        report = cr(y_test, y_predict, output_dict=True)\n",
    "        confusion_mat = confusion_matrix(y_test, y_predict)\n",
    "        print(\"==================\",clf,\"================\",sampling)\n",
    "        print(cr(y_test, y_predict))\n",
    "        print(confusion_matrix(y_test, y_predict))\n",
    "        results.append([clf, user ,normalize,sampling,report, confusion_mat])\n",
    "        \n",
    "service_type_results  = pd.DataFrame(results, columns = service_table_columns)\n",
    "service_type_results.to_csv(\"./service_type_results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results for different test sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_list = list(set(df['userid']))\n",
    "results = []\n",
    "normalize = 'Yes'\n",
    "sampling = \"No\"\n",
    "classifiers = {'ExtraTrees': ExtraTreesClassifier()}\n",
    "tsizes_table_columns = pkl.load(open('./tsizes_table_columns.pkl', 'rb'))\n",
    "\n",
    "for i in range(1, len(user_list) + 1):    \n",
    "    data_testSizes = data[data['userid'].isin(user_list[:i])]\n",
    "    X = data_testSizes[action_type_feats]\n",
    "    y = data_testSizes['actiontype']\n",
    "    X = scale.fit_transform(X)\n",
    "    tsize = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "    \n",
    "    for clf in classifiers:\n",
    "        for size in tsize:\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = size )\n",
    "            curr_clas = classifiers[clf]\n",
    "            \n",
    "            print('Users', user_list[:i], 'Normalize ', normalize , 'Classifier ', clf, 'TestSize', size, 'Df shape', data_testSizes.shape)\n",
    "            curr_clas.fit(X_train, y_train)\n",
    "            y_predict = curr_clas.predict(X_test)\n",
    "            \n",
    "            report = cr(y_test, y_predict, target_names=['benign','malicious'], output_dict=True)\n",
    "            confusion_mat = confusion_matrix(y_test, y_predict)\n",
    "            auc_score = roc_auc_score(y_test, y_predict)\n",
    "\n",
    "            results.append([clf,\n",
    "                            user_list[:i],\n",
    "                            i,\n",
    "                            size,\n",
    "                            normalize,\n",
    "                            sampling,\n",
    "                            report['benign']['precision'],\n",
    "                            report['benign']['recall'],\n",
    "                            report['benign']['f1-score'],\n",
    "                            report['benign']['support'],\n",
    "                            report['malicious']['precision'],\n",
    "                            report['malicious']['recall'],\n",
    "                            report['malicious']['f1-score'],\n",
    "                            report['malicious']['support'],\n",
    "                            report['macro avg']['precision'],\n",
    "                            report['macro avg']['recall'],\n",
    "                            report['macro avg']['f1-score'],\n",
    "                            report['macro avg']['support'],\n",
    "                            report['weighted avg']['precision'],\n",
    "                            report['weighted avg']['recall'],\n",
    "                            report['weighted avg']['f1-score'],\n",
    "                            report['weighted avg']['support'],\n",
    "                            report['accuracy'],\n",
    "                            confusion_mat[0][0],\n",
    "                            confusion_mat[0][1],\n",
    "                            confusion_mat[1][0],\n",
    "                            confusion_mat[1][1],\n",
    "                            auc_score, X_train.shape])\n",
    "\n",
    "varying_test_size_results  = pd.DataFrame(results, columns = tsizes_table_columns)\n",
    "varying_test_size_results['FOR'] = varying_test_size_results['FalseNegative'] / (varying_test_size_results['FalseNegative'] + varying_test_size_results['TrueNegative'])\n",
    "varying_test_size_results['FPR'] = varying_test_size_results['FalsePositive'] / (varying_test_size_results['FalsePositive'] + varying_test_size_results['TrueNegative'])\n",
    "varying_test_size_results.to_csv('./varying_test_size_results.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
